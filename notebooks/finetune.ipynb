{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow relative import from parent directory\n",
    "import sys  \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning models\n",
    "\n",
    "Alright, we're here, sittin' front of the 'puter,\n",
    "\n",
    "I want you to show me how you train a transformer!\n",
    "\n",
    "Adjust the rate! (Adjust the rate!)\n",
    "\n",
    "Now backpropagate! (Now backpropagate!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name used to identify the model / tensorboard run\n",
    "training_run_name = \"example_training_run\"\n",
    "\n",
    "# Output datasets for training / evaluation\n",
    "dataset_train = \"../datasets/train.pkl\"\n",
    "dataset_test = \"../datasets/test.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I say \"load, load, load,\" you say \"train, train, train!\"\n",
    "\n",
    "No pause in between, let's ignite our brain!\n",
    "\n",
    "Load the encoder! (Load the encoder!)\n",
    "\n",
    "Train it swift! (Train it swift!)\n",
    "\n",
    "Train it swift! (Train it swift!)\n",
    "\n",
    "Now load the encoder! (Now load the encoder!)\n",
    "\n",
    "Sure, we've charted our course, no doubt to sow,\n",
    "\n",
    "But onward we march, with momentum's flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beatlearning.tokenizers import BEaRTTokenizer\n",
    "from beatlearning.configs import QuaverBEaRT\n",
    "from beatlearning.models import BEaRT\n",
    "\n",
    "# model config is based on the tokenizer's settings\n",
    "model_config = QuaverBEaRT()\n",
    "tokenizer = BEaRTTokenizer(model_config)\n",
    "\n",
    "# init transformer model based on tokenizer\n",
    "model = BEaRT(tokenizer)\n",
    "model.num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning's like driving, with skill and flair,\n",
    "\n",
    "Rev up your model, it's your journey to declare!\n",
    "\n",
    "With each tweak and adjustment, you'll go far,\n",
    "\n",
    "In the world of deep learning, you'll become a star!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally load previous checkpoint (checkpoints contain both model weights and trainer status)\n",
    "model.load(\"../models/checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woh ho ho ho! Hold the script!\n",
    "\n",
    "Gotta load the data, don't wanna slip.\n",
    "\n",
    "Do you grasp why we paused the run? (Do I grasp why we paused the run?)\n",
    "\n",
    "Guess... (Guess...)\n",
    "\n",
    "What... (What...)\n",
    "\n",
    "I forgot to load the dataset... (You forgot to load the dataset...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "import dill as pickle\n",
    "\n",
    "with open(dataset_train, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open(dataset_test, \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard logs, your visual aide,\n",
    "\n",
    "Tracking metrics and losses, a parade.\n",
    "\n",
    "Optimize your model, with insights clear,\n",
    "\n",
    "With each training session, it's victory near!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model trainer\n",
    "\n",
    "from beatlearning.configs import TrainingConfig\n",
    "from beatlearning.trainers import BEaRTTrainer\n",
    "\n",
    "training_config = TrainingConfig()\n",
    "\n",
    "trainer = BEaRTTrainer(training_run_name,\n",
    "                       model,\n",
    "                       train_data,\n",
    "                       test_data,\n",
    "                       training_config)\n",
    " \n",
    "\"CUDA ðŸ˜Ž\" if trainer.is_cuda_available else \"CPU ðŸ¤·\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved checkpoints, for where you left,\n",
    "\n",
    "Continue fine-tuning, with skills deft.\n",
    "\n",
    "Recover your progress, with each stride,\n",
    "\n",
    "And monitor with TensorBoard, your training's guide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally load previous checkpoint (checkpoints contain both model weights and trainer status)\n",
    "# NOTE: loading a checkpoint will allow to continue from the last epoch: all results will be appended to the same TensorBoard run\n",
    "last_epoch = model.load(\"../models/checkpoint.pt\")\n",
    "last_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust your learning rate, not too fast nor slow,\n",
    "\n",
    "With a schedule or manually, watch it grow.\n",
    "\n",
    "Increase epochs for convergence, make it last,\n",
    "\n",
    "And apply regularization, to avoid overcast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use 'last_epoch + 1' instead of 0 to continue a loadede model from its last epoch\n",
    "for epoch in range(0, trainer.config.num_epochs):\n",
    "    trainer.train(epoch)\n",
    "    trainer.test(epoch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you know why the training's stopped? (Do I know why the training's stopped?)\n",
    "\n",
    "That's because you just got your model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
