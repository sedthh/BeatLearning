{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow relative import from parent directory\n",
    "import sys  \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert OSU files to the Intermediate Beatmap Format\n",
    "\n",
    "Data! Preprocess! It's all in the code!\n",
    "\n",
    "If you wanna train me, here's the road:\n",
    "\n",
    "All the steps I guide you through, to succeed it's true,\n",
    "\n",
    "But fear not, you'll master this too, let's begin anew!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSZ files path\n",
    "input_path = \"songs/\"\n",
    "# Intermediate Beatmap File + Audio output path\n",
    "output_path = \"ibfs/\"\n",
    "# Output dataset for training / evaluation based on the contents of output_path\n",
    "dataset_file = \"datasets/example.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, gather your data, make sure it's clean and neat,\n",
    "\n",
    "Each sample's features, labels complete.\n",
    "\n",
    "Then preprocess, normalize, and scale,\n",
    "\n",
    "To ensure our model won't fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all OSZ files and OSU files within to the Intermediat Beatmap Format\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from beatlearning.utils import IntermediateBeatmapFormat\n",
    "from beatlearning.converters import OsuBeatmapConverter\n",
    "\n",
    "converter = OsuBeatmapConverter()\n",
    "for file in tqdm(os.listdir(input_path)):\n",
    "    if file.lower().endswith(\".osz\"):\n",
    "        # OSZ files can contain multiple OSU beatmap files, extract them all to a folder based on the file name\n",
    "        new_folder = os.path.splitext(os.path.basename(file))[0]\n",
    "        converter.convert(os.path.join(input_path, file), \n",
    "                        os.path.join(output_path, new_folder), \n",
    "                        os.path.join(output_path, new_folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! Before we tokenize, an intermediate format we create,\n",
    "\n",
    "Between raw data and tokens, it's great.\n",
    "\n",
    "A custom format, designed for our ease,\n",
    "\n",
    "A metadata dictionary and a Pandas DataFrame, oh please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model (you will need to use the EXACT same config / tokenizer throughout training and inference)\n",
    "from beatlearning.tokenizers import BEaRTTokenizer\n",
    "from beatlearning.configs import QuaverBEaRT\n",
    "\n",
    "config = QuaverBEaRT()\n",
    "tokenizer = BEaRTTokenizer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for generating data, let's make it diverse,\n",
    "\n",
    "With augmentation techniques, we'll immerse.\n",
    "\n",
    "Rotate, flip, and shift, or add some noise,\n",
    "\n",
    "To ensure our model's robust, that's our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dataset from the converted beatmaps\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "from beatlearning.utils import BEaRTDataset\n",
    "\n",
    "dataset = BEaRTDataset(tokenizer,     # pass the tokenizer\n",
    "                       augment=True)  # set to False for evaluation sets\n",
    "np.random.seed(1234567)\n",
    "for folder in tqdm(os.listdir(output_path)):\n",
    "    # find all IntermediateBeatmapFormat files and the mp3 audio\n",
    "    ibfs, mp3 = [], None\n",
    "    for file in os.listdir(os.path.join(output_path, folder)):\n",
    "        # multiple IBF files can share the same audio\n",
    "        if file.endswith(\".ibf\"):\n",
    "            ibfs.append(IntermediateBeatmapFormat(os.path.join(output_path, folder, file)))\n",
    "        elif file.endswith(\".mp3\"):\n",
    "            mp3 = os.path.join(output_path, folder, file)\n",
    "    if ibfs and mp3:\n",
    "        # NOTE: you can add offsets += [0.01, 0.02 ... 0.09] for ADDITIONAL augmentation purposes\n",
    "        # this will nudge the timing in a way, that 10ms quantized events will result in different tokens\n",
    "        offsets = [0.0]\n",
    "        dataset.add(ibfs, mp3, \n",
    "                    offsets=offsets,\n",
    "                    ignore_lead_in=True)\n",
    "# write dataset\n",
    "with open(dataset_file, \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "print(f\"{os.path.getsize(dataset_file) / (1024 ** 3):.3f}GB ({len(dataset)} rows)\")\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for today\n",
    "\n",
    "Good job! You can move on to the next stage now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
